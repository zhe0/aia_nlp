{"cells":[{"cell_type":"markdown","metadata":{"id":"44181f5c"},"source":["### Hands on tutorial of Graph Representation Learning\n","\n","In this lecture, we will go through the following topics\n","1. Graph structued data in Python\n","2. GNN package - Pytorch-Geometric introduction\n","3. Representation in Graphs - node2vec, GCN\n","4. GNN with downstrean tasks\n","5. GNN for text classification\n"],"id":"44181f5c"},{"cell_type":"code","execution_count":null,"metadata":{"id":"1cfbad83"},"outputs":[],"source":["import os\n","import torch\n","import numpy as np\n","os.environ['TORCH'] = torch.__version__\n","print(torch.__version__)\n","\n","!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n","!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n","!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n","!pip install -q torch-cluster -f https://data.pyg.org/whl/torch-${TORCH}.html\n","\n","from torch_geometric.nn import Node2Vec\n","import torch_cluster\n","import os.path as osp\n","import matplotlib.pyplot as plt\n","from sklearn.manifold import TSNE\n","from torch_geometric.datasets import Planetoid\n","from torch_geometric.transforms import NormalizeFeatures\n","from tqdm.notebook import tqdm\n","random_walk = torch.ops.torch_cluster.random_walk"],"id":"1cfbad83"},{"cell_type":"markdown","metadata":{"id":"824a7d3a"},"source":["# Graph Representation Learning\n","The goal of Graph Representation Learning aims at learning **embedding vectors** for each node that preserves the proximity in graphs. <br>\n","To demonstrate, we make use of the `KarateClud` dataset, as we introduced before.\n","\n","![](https://i.imgur.com/oQv59aR.png)"],"id":"824a7d3a"},{"cell_type":"code","execution_count":null,"metadata":{"id":"198babee","collapsed":true},"outputs":[],"source":["from torch_geometric.datasets import KarateClub\n","\n","dataset = KarateClub()\n","print(f'Dataset: {dataset}:')\n","print('======================')\n","print(f'Number of graphs: {len(dataset)}')\n","print(f'Number of features: {dataset.num_features}')\n","print(f'Number of classes: {dataset.num_classes}')\n","\n","\n","data = dataset[0]  # Get the first graph object.\n","\n","print(data)\n","print('==============================================================')\n","\n","# Gather some statistics about the graph.\n","print(f'Number of nodes: {data.num_nodes}')\n","print(f'Number of edges: {data.num_edges}')\n","print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n","print(f'Number of training nodes: {data.train_mask.sum()}')\n","print(f'Training node label rate: {int(data.train_mask.sum()) / data.num_nodes:.2f}')\n","print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n","print(f'Has self-loops: {data.has_self_loops()}')\n","print(f'Is undirected: {data.is_undirected()}')"],"id":"198babee"},{"cell_type":"code","execution_count":null,"metadata":{"id":"a3111c17"},"outputs":[],"source":["model = Node2Vec(data.edge_index, embedding_dim=16, \n","                 walk_length=10,                        # lenght of rw\n","                 context_size=10, walks_per_node=80,\n","                 num_negative_samples=1,\n","                 p=4,q=1,\n","                 sparse=True)"],"id":"a3111c17"},{"cell_type":"code","execution_count":null,"metadata":{"id":"e12afacf"},"outputs":[],"source":["loader = model.loader(batch_size=128, shuffle=True, num_workers=4)"],"id":"e12afacf"},{"cell_type":"code","execution_count":null,"metadata":{"id":"cced9b22"},"outputs":[],"source":["for idx, (pos_nodes, neg_nodes) in enumerate(loader):\n","    print(idx, pos_nodes.shape, neg_nodes.shape)"],"id":"cced9b22"},{"cell_type":"code","execution_count":null,"metadata":{"id":"e2d83077"},"outputs":[],"source":["print(pos_nodes)"],"id":"e2d83077"},{"cell_type":"code","execution_count":null,"metadata":{"id":"f3aa4520"},"outputs":[],"source":["print(neg_nodes)"],"id":"f3aa4520"},{"cell_type":"markdown","metadata":{"id":"acd8f121"},"source":["## Visualization"],"id":"acd8f121"},{"cell_type":"code","execution_count":null,"metadata":{"id":"a7b25d14"},"outputs":[],"source":["import networkx as nx \n","edge_tuples = [tuple(x) for x in data.edge_index.numpy().transpose()]\n","G = nx.from_edgelist(edge_tuples)\n","pos = nx.spring_layout(G, center=[0.5, 0.5])\n","nx.set_node_attributes(G, pos, 'pos')"],"id":"a7b25d14"},{"cell_type":"code","execution_count":null,"metadata":{"id":"5baa7f2d"},"outputs":[],"source":["nodelist = next(enumerate(loader))[1][0][0].tolist()\n","walk = nx.path_graph(len(nodelist))\n","nx.set_node_attributes(walk, {idx: pos[node_id] for idx, node_id in enumerate(nodelist)}, 'pos')\n","\n","fig = plt.figure(figsize=(20, 10))\n","ax = fig.add_subplot(1, 2, 1)\n","nx.draw_networkx(G, \n","   ax=ax,\n","   pos=nx.get_node_attributes(G, 'pos'), \n","   node_size=550,\n","   node_color='b',\n","   font_color=\"white\",\n","   font_weight='bold'\n","                )\n","nx.draw(walk, \n","        node_size=40,\n","        node_color='r',\n","        ax=ax,\n","        pos=nx.get_node_attributes(walk, 'pos'), \n","        width=2,\n","        edge_color='r') \n","ax = fig.add_subplot(1, 2, 2)\n","nx.draw(walk, \n","        node_size=40,\n","        node_color='r',\n","        ax=ax,\n","        pos=nx.get_node_attributes(walk, 'pos'), \n","        width=2,\n","        edge_color='r') \n"],"id":"5baa7f2d"},{"cell_type":"markdown","metadata":{"id":"3fec180d"},"source":["## Training\n","Let's create a `Node2vec` model from the `PyG` libiary, which provides the dataloader for creating training instances as well as calculating the objective function. <br>\n","The objective function is defined as follows\n","\n","\\begin{equation}\n","L(\\Theta) = \\log \\left ( \\sigma (z_u^{\\top} z_v)  \\right) - \\sum_{i=1}^k \\log \\left ( \\sigma (z_u^{\\top} z_{n_i})  \\right), n_i \\sim P_V\n","\\end{equation}"],"id":"3fec180d"},{"cell_type":"code","execution_count":null,"metadata":{"id":"c9a82e18"},"outputs":[],"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","node2vec_model = Node2Vec(data.edge_index, embedding_dim=2, walk_length=10,\n","                 context_size=4, walks_per_node=80,\n","                 num_negative_samples=5, p=4, q=1, sparse=True).to(device)\n","\n","loader = node2vec_model.loader(batch_size=128, shuffle=True, num_workers=2)\n","optimizer = torch.optim.SparseAdam(list(node2vec_model.parameters()), lr=0.01)"],"id":"c9a82e18"},{"cell_type":"code","execution_count":null,"metadata":{"id":"2a550791"},"outputs":[],"source":["def train():\n","    node2vec_model.train()\n","    total_loss = 0\n","    for pos_rw, neg_rw in tqdm(loader):\n","        optimizer.zero_grad()\n","        loss = node2vec_model.loss(pos_rw.to(device), neg_rw.to(device))\n","        loss.backward()\n","        optimizer.step()\n","        total_loss += loss.item()\n","    return total_loss / len(loader)"],"id":"2a550791"},{"cell_type":"code","execution_count":null,"metadata":{"id":"c2f41608","scrolled":true},"outputs":[],"source":["for epoch in range(1, 201):\n","    loss = train()\n","    print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}')"],"id":"c2f41608"},{"cell_type":"code","execution_count":null,"metadata":{"id":"ajVLm-JoGaCa"},"outputs":[],"source":["# obtain labels for each nodes\n","G = nx.karate_club_graph()\n","labels = np.asarray([G.nodes[i]['club'] != 'Mr. Hi' for i in G.nodes]).astype(np.int64)\n","\n","# color mapping\n","mapping = {0:\"purple\",1:\"green\"}\n","node_colors = [mapping[i] for i in labels]"],"id":"ajVLm-JoGaCa"},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":false,"id":"MLBpqiFuGaCa"},"outputs":[],"source":["fig = plt.figure(figsize=(20, 10))\n","\n","# plot the original graph\n","ax = fig.add_subplot(1, 2, 1)\n","nx.draw_networkx(G, \n","   ax=ax,\n","   pos = nx.spring_layout(G, center=[0.5, 0.5]), \n","   node_size=550,\n","   node_color=node_colors,\n","   font_color=\"white\",\n","   font_weight='bold'\n","                )\n","\n","# visualize embedding in 2D space\n","ax = fig.add_subplot(1, 2, 2)\n","with torch.no_grad():\n","    embedding = node2vec_model(torch.arange(data.num_nodes, device=device))\n","    embedding = embedding.cpu().numpy()\n","    pos = {i:v for i,v in enumerate(embedding)}\n","\n","# make plots\n","nx.draw_networkx_nodes(G, \n","   ax=ax,\n","   pos=pos, \n","   node_size=550,\n","   node_color=node_colors,\n",")\n","\n","nx.draw_networkx_labels(\n","    G,\n","    pos=pos, \n","   font_color=\"white\",\n","   font_weight='bold',\n","   )\n","plt.show()"],"id":"MLBpqiFuGaCa"},{"cell_type":"markdown","metadata":{"id":"TRsvTcnyGaCa"},"source":["# Practice: Representation learning on large graphs\n","<!-- This tutorial will teach you how to apply **Graph Neural Networks (GNNs) to the task of node classification**.\n","Here, we are given the ground-truth labels of only a small subset of nodes, and want to infer the labels for all the remaining nodes (*transductive learning*). -->\n","\n","To demonstrate, we make use of the `Cora` dataset, which is a **citation network** where nodes represent documents.\n","Each node is described by a 1433-dimensional bag-of-words feature vector.\n","Two documents are connected if there exists a citation link between them.\n","The task is to infer the category of each document (7 in total).<br>\n","\n","This dataset was first introduced by [Yang et al. (2016)](https://arxiv.org/abs/1603.08861) as one of the datasets of the `Planetoid` benchmark suite.\n","We again can make use [PyTorch Geometric](https://github.com/rusty1s/pytorch_geometric) for an easy access to this dataset via [`torch_geometric.datasets.Planetoid`](https://pytorch-geometric.readthedocs.io/en/latest/modules/datasets.html#torch_geometric.datasets.Planetoid)\n","\n","Another interesting application citation graphs could be found at [connected papers](https://www.connectedpapers.com/)."],"id":"TRsvTcnyGaCa"},{"cell_type":"code","execution_count":null,"metadata":{"id":"OmQYHXNAGaCa"},"outputs":[],"source":["from torch_geometric.datasets import Planetoid\n","\n","dataset = 'Cora'\n","path = osp.join('.', 'data', dataset)\n","dataset = Planetoid(root=path, name='Cora', transform=NormalizeFeatures())\n","\n","print()\n","print(f'Dataset: {dataset}:')\n","print('======================')\n","print(f'Number of graphs: {len(dataset)}')\n","print(f'Number of features: {dataset.num_features}')\n","print(f'Number of classes: {dataset.num_classes}')\n","\n","data = dataset[0]  # Get the first graph object.\n","\n","print()\n","print(data)\n","print('===========================================================================================================')\n","\n","# Gather some statistics about the graph.\n","print(f'Number of nodes: {data.num_nodes}')\n","print(f'Number of edges: {data.num_edges}')\n","print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n","print(f'Number of training nodes: {data.train_mask.sum()}')\n","print(f'Training node label rate: {int(data.train_mask.sum()) / data.num_nodes:.2f}')\n","print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n","print(f'Has self-loops: {data.has_self_loops()}')\n","print(f'Is undirected: {data.is_undirected()}')"],"id":"OmQYHXNAGaCa"},{"cell_type":"markdown","metadata":{"id":"M_8rJqi6GaCa"},"source":["Overall, this dataset is quite similar to the previously used [`KarateClub`](https://pytorch-geometric.readthedocs.io/en/latest/modules/datasets.html#torch_geometric.datasets.KarateClub) network.\n","We can see that the `Cora` network holds 2,708 nodes and 10,556 edges, resulting in an average node degree of 3.9.\n","For training this dataset, we are given the ground-truth categories of 140 nodes (20 for each class).\n","This results in a training node label rate of only 5%.\n","\n","In contrast to `KarateClub`, this graph holds the additional attributes `val_mask` and `test_mask`, which denotes which nodes should be used for validation and testing. We can further see that this network is undirected, and that there exists no isolated nodes (each document has at least one citation).\n","<!-- Furthermore, we make use of **[data transformations](https://pytorch-geometric.readthedocs.io/en/latest/notes/introduction.html#data-transforms) via `transform=NormalizeFeatures()`**.\n","Transforms can be used to modify your input data before inputting them into a neural network, *e.g.*, for normalization or data augmentation.\n","Here, we [row-normalize](https://pytorch-geometric.readthedocs.io/en/latest/modules/transforms.html#torch_geometric.transforms.NormalizeFeatures) the bag-of-words input feature vectors. -->\n"],"id":"M_8rJqi6GaCa"},{"cell_type":"markdown","metadata":{"id":"KF8nWfbsGaCb"},"source":["## Practice: learning node embeddings for each node (document)\n","1. Please use node2vec to learn embeddings on `Cora` dataset\n","2. Define your node2vec model configurations\n","3. Training\n","4. Vistualization nodes in 2D space. The color of node indicates the \"label\" of the node. What did you observe in the figure?"],"id":"KF8nWfbsGaCb"},{"cell_type":"code","execution_count":null,"metadata":{"id":"vpseOyjaGaCb"},"outputs":[],"source":["# TODO: your code here!\n","# define your node2vec model and train it to obtain node embeddings!\n","node2vec_model = None\n","loader = None\n","optimizer = None"],"id":"vpseOyjaGaCb"},{"cell_type":"code","execution_count":null,"metadata":{"id":"NzyVa6uyGaCb"},"outputs":[],"source":["# define your training loop here"],"id":"NzyVa6uyGaCb"},{"cell_type":"code","execution_count":null,"metadata":{"id":"dQ1j67lIGaCb"},"outputs":[],"source":["# after your model is learned, run the following scripts and see what you get!\n","@torch.no_grad()\n","def plot_points(colors):\n","    node2vec_model.eval()\n","    z = node2vec_model(torch.arange(data.num_nodes, device=device))\n","    z = TSNE(n_components=2).fit_transform(z.cpu().numpy())\n","    y = data.y.cpu().numpy()\n","\n","    plt.figure(figsize=(8, 8))\n","    for i in range(dataset.num_classes):\n","        plt.scatter(z[y == i, 0], z[y == i, 1], s=20, color=colors[i])\n","    plt.axis('off')\n","    plt.show()\n","\n","colors = [\n","    '#ffc0cb', '#bada55', '#008080', '#420420', '#7fe5f0', '#065535',\n","    '#ffd700'\n","]\n","plot_points(colors)"],"id":"dQ1j67lIGaCb"},{"cell_type":"markdown","metadata":{"id":"547c3d9f"},"source":["# Application of GRL: Semi-supervised document classification\n","As mentioned previously, `Cora` contains 2K documents of scientific papers. However, **only 5% of documents are given the ground-truth labels** in the training set while the remaining documents are unlabeled.\n","\n","Since each paper(node) is described by a 1433-dimensional bag-of-words feature vector, let's first build a document classifier and see how it works!"],"id":"547c3d9f"},{"cell_type":"code","execution_count":null,"metadata":{"id":"c9af8502"},"outputs":[],"source":["import torch\n","from torch.nn import Linear\n","import torch.nn.functional as F\n","\n","class MLP(torch.nn.Module):\n","    def __init__(self, hidden_channels):\n","        super(MLP, self).__init__()\n","        torch.manual_seed(12345)\n","        self.lin1 = Linear(dataset.num_features, hidden_channels)\n","        self.lin2 = Linear(hidden_channels, dataset.num_classes)\n","\n","    def forward(self, x):\n","        x = self.lin1(x)\n","        x = x.relu()\n","        x = self.lin2(x)\n","        return x"],"id":"c9af8502"},{"cell_type":"code","execution_count":null,"metadata":{"id":"1b20ee47","scrolled":true},"outputs":[],"source":["model = MLP(hidden_channels=64)\n","criterion = torch.nn.CrossEntropyLoss()  # Define loss criterion.\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)  # Define optimizer.\n","\n","def train():\n","    model.train()\n","    optimizer.zero_grad()  \n","    out = model(data.x)  \n","    loss = criterion(out[data.train_mask], data.y[data.train_mask])  # Compute the loss solely based on the training nodes.\n","    loss.backward()  \n","    optimizer.step() \n","    return loss\n","\n","for epoch in range(1, 201):\n","    loss = train()\n","    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')"],"id":"1b20ee47"},{"cell_type":"code","execution_count":null,"metadata":{"id":"81d8b885"},"outputs":[],"source":["@torch.no_grad()\n","def test():\n","    model.eval()\n","    out = model(data.x)\n","    pred = out.argmax(dim=1)  # Use the class with highest probability.\n","    test_correct = pred[data.test_mask] == data.y[data.test_mask]  # Check against ground-truth labels.\n","    test_acc = int(test_correct.sum()) / int(data.test_mask.sum())  # Derive ratio of correct predictions.\n","    return test_acc\n","\n","test_acc = test()\n","print(f'Test Accuracy: {test_acc:.4f}')"],"id":"81d8b885"},{"cell_type":"markdown","metadata":{"id":"e0885073"},"source":["## Improving document classification with node embedding\n","It seems that the MLP model with the Bag-of-Word feature cannot perform well in the semi-supervised scenario.<br>\n","Can we make use of the graph structure between documents and generate additional features in unsupervised fashion where the unlabeled document could provide some signals for us."],"id":"e0885073"},{"cell_type":"code","execution_count":null,"metadata":{"id":"4f2e95c5"},"outputs":[],"source":["# Here we use a simple Logistic regression classifier for document classification\n","from sklearn.linear_model import LogisticRegression"],"id":"4f2e95c5"},{"cell_type":"code","execution_count":null,"metadata":{"id":"204c78aa"},"outputs":[],"source":["with torch.no_grad():\n","    node2vec_model.eval()\n","    # the node embedding is actually the document embedding learned from graph structure\n","    node_embedding = node2vec_model().cpu().numpy() \n","    print(node_embedding.shape)"],"id":"204c78aa"},{"cell_type":"code","execution_count":null,"metadata":{"id":"985b8194"},"outputs":[],"source":["# Training\n","clf = LogisticRegression() # create logistic regression model\n","clf.fit(node_embedding[data.train_mask,:], data.y[data.train_mask]) # fit on training set\n","\n","# Testing\n","test_acc = clf.score(node_embedding[data.test_mask,:], data.y[data.test_mask])\n","print(f'Test Accuracy: {test_acc:.4f}')"],"id":"985b8194"},{"cell_type":"markdown","metadata":{"id":"587f5478"},"source":["Wow! We improve the testing accuracy from ~60%(BOW+MLP) to 70% with network embedding(without using the BOW features) !\n","\n","\n","Can we further improve the performance by considering both **network structure and BOW features simultaneously?**"],"id":"587f5478"},{"cell_type":"code","execution_count":null,"metadata":{"id":"0481a36c"},"outputs":[],"source":["# training data\n","train_bow = data.x[data.train_mask].numpy()\n","train_node_embedding = node_embedding[data.train_mask,:]\n","train_features = np.hstack([train_bow,train_node_embedding])\n","\n","# testing data\n","test_bow = data.x[data.test_mask].numpy()\n","test_node_embedding = node_embedding[data.test_mask,:]\n","test_features = np.hstack([test_bow,test_node_embedding])\n","\n","print(\"Training feature:\",train_features.shape)\n","print(\"Testing feature:\",test_features.shape)"],"id":"0481a36c"},{"cell_type":"code","execution_count":null,"metadata":{"id":"280480fe"},"outputs":[],"source":["# Training\n","clf = LogisticRegression() # create logistic regression model\n","clf.fit(train_features, data.y[data.train_mask]) # fit on training set\n","\n","# Testing\n","test_acc = clf.score(test_features, data.y[data.test_mask])\n","print(f'Test Accuracy: {test_acc:.4f}')"],"id":"280480fe"},{"cell_type":"markdown","metadata":{"id":"66727699"},"source":["Not looking good...\n","\n","Don't worry! We will introduce how the state-of-the-art solution: **Graph Neural Network(GNN)** solves this issue in the following topic."],"id":"66727699"},{"cell_type":"markdown","metadata":{"id":"b2b10edc"},"source":["# Application\\#2: Citation recommendation (link prediction)\n","\n","In the citation prediction problem, we are given the citation graph where documents connect with each other if one cites another. <br>\n","The goal in to recommend pontential citatations for specific papers. In other words, we're try to find a missing link between documents. <br>\n","This problem is also a famous task in graph mining called \"link prediction\" as people would like to know the potential links between nodes.<br>"],"id":"b2b10edc"},{"cell_type":"code","execution_count":null,"metadata":{"id":"553465d6"},"outputs":[],"source":["import os.path as osp\n","\n","import torch\n","from sklearn.metrics import roc_auc_score\n","\n","import torch_geometric.transforms as T\n","from torch_geometric.datasets import Planetoid\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","transform = T.Compose([\n","    T.NormalizeFeatures(),\n","    T.RandomLinkSplit(num_val=0.05, num_test=0.1, is_undirected=True,\n","                      add_negative_train_samples=True),\n","])\n","dataset = Planetoid(path, name='Cora', transform=transform)\n","# After applying the `RandomLinkSplit` transform, the data is transformed from\n","# a data object to a list of tuples (train_data, val_data, test_data), with\n","# each element representing the corresponding split.\n","train_data, val_data, test_data = dataset[0]"],"id":"553465d6"},{"cell_type":"code","execution_count":null,"metadata":{"id":"e56bae91"},"outputs":[],"source":["print(\"--------Training data------\")\n","print(train_data)\n","print(\"Training edges:\")\n","print(train_data.edge_label_index)\n","print(\"Labels\")\n","print(train_data.edge_label)\n","\n","print()\n","\n","print(\"--------Validation data------\")\n","print(val_data)\n","print(\"Validation edges:\")\n","print(val_data.edge_label_index)\n","print(\"Labels\")\n","print(val_data.edge_label[:10])\n","\n","print()\n","print(\"--------Testing data------\")\n","print(test_data)\n","print(\"Testing edges:\")\n","print(test_data.edge_label_index)\n","print(\"Labels\")\n","print(test_data.edge_label)"],"id":"e56bae91"},{"cell_type":"markdown","metadata":{"id":"7f1cc489"},"source":["## Obtain node embedding with training edges"],"id":"7f1cc489"},{"cell_type":"code","execution_count":null,"metadata":{"id":"1b36d8b4"},"outputs":[],"source":["# Create node2vec model to obtain node embeddings\n","# Note: We only use the edges in training data (since we're predicting the remaining edges)\n","node2vec_model = Node2Vec(train_data.edge_index, embedding_dim=128, walk_length=20,\n","                 context_size=10, walks_per_node=10,\n","                 num_negative_samples=1, p=1, q=1, sparse=True).to(device)\n","\n","loader = node2vec_model.loader(batch_size=128, shuffle=True, num_workers=4)\n","optimizer = torch.optim.SparseAdam(list(node2vec_model.parameters()), lr=0.01)"],"id":"1b36d8b4"},{"cell_type":"code","execution_count":null,"metadata":{"id":"bb86b710"},"outputs":[],"source":["def train():\n","    node2vec_model.train()\n","    total_loss = 0\n","    for pos_rw, neg_rw in tqdm(loader):\n","        optimizer.zero_grad()\n","        loss = node2vec_model.loss(pos_rw.to(device), neg_rw.to(device))\n","        loss.backward()\n","        optimizer.step()\n","        total_loss += loss.item()\n","    return total_loss / len(loader)"],"id":"bb86b710"},{"cell_type":"code","execution_count":null,"metadata":{"id":"1d8fe4f4"},"outputs":[],"source":["for epoch in range(1, 201):\n","    loss = train()\n","    print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}')"],"id":"1d8fe4f4"},{"cell_type":"markdown","metadata":{"id":"57ef7ddd"},"source":["## Use the node embedding as feature to train link prediction model\n","An interesting issue here is: Node2vec gives us the **\"node-level\"** features while we need the **\"edge-level\"** information to determin whether a edge exist or not. <br>\n","Here's some candidate:\n","1. Concatenation of node A and node B's embeddings \n","2. Elementwise-subtract between node A and node B's embeddings \n","3. Elementwise-product between node A and node B's embeddings \n","\n","Empirically, people use the third approach which leads to the best performance!"],"id":"57ef7ddd"},{"cell_type":"code","execution_count":null,"metadata":{"id":"86782d3a"},"outputs":[],"source":["with torch.no_grad():\n","    node2vec_model.eval()\n","    node_embedding = node2vec_model().cpu().numpy() \n","    print(node_embedding.shape)"],"id":"86782d3a"},{"cell_type":"code","execution_count":null,"metadata":{"id":"7e40b849"},"outputs":[],"source":["# obtaining embedding feautre\n","train_embedding_pair = node_embedding[train_data.edge_label_index.T]\n","print(train_embedding_pair.shape)\n","\n","# apply element-wise product to represent the \"edge\" feature\n","train_features = train_embedding_pair[:,0,:] * train_embedding_pair[:,1,:]\n","print(train_features.shape) # we have 8976 examples with 128 dimensional feature"],"id":"7e40b849"},{"cell_type":"code","execution_count":null,"metadata":{"id":"fff835f5"},"outputs":[],"source":["# use LR as classifier for link prediction\n","link_clf = LogisticRegression()\n","link_clf.fit(train_features,train_data.edge_label.numpy())"],"id":"fff835f5"},{"cell_type":"code","execution_count":null,"metadata":{"id":"28afd692"},"outputs":[],"source":["# feature for predicting testing edges\n","test_embedding_pair = node_embedding[test_data.edge_label_index.T]\n","print(test_embedding_pair.shape)\n","\n","# apply element-wise product to represent the \"edge\" feature\n","test_features = test_embedding_pair[:,0,:] * test_embedding_pair[:,1,:]\n","print(test_features.shape) "],"id":"28afd692"},{"cell_type":"code","execution_count":null,"metadata":{"id":"6053fa53"},"outputs":[],"source":["# calculate link prediction accuracy \n","acc = link_clf.score(test_features, test_data.edge_label.numpy())\n","print(f\"Accuracy score:{acc:.4f}\")\n","roc = roc_auc_score(test_data.edge_label.numpy(), link_clf.predict_proba(test_features)[:,1])\n","print(f\"ROC score:{roc:.4f}\")"],"id":"6053fa53"}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":5}