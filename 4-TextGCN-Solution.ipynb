{"cells":[{"cell_type":"markdown","id":"65c49127","metadata":{"id":"65c49127"},"source":["# Text classification with GNN: TextGCN\n","In this tutorial, we will go through the details of how to implement the TextGCN model proposed by Liang et al. 2019. <br>\n","\n","From the previous lectures, we have seen how the GNN models work to extract graph and node representations in unsupervised and supervised learning tasks.<br>\n","Here we demonstrate how GNNs could be applied on learning document embeddings.\n","Text GCN is a model which allows us to use a graph neural network for text classification where the type of network is convolutional. The below figure is a representation of the adaptation of convolutional graphs using the Text GCN.\n","\n","![](https://149695847.v2.pressablecdn.com/wp-content/uploads/2021/11/image-15-1024x412.png)\n"]},{"cell_type":"markdown","id":"23fb065b","metadata":{"id":"23fb065b"},"source":["The model in Text GCN takes the input in the form of an identity matrix so that every word can be represented as the one-hot vector. To generate the TF-IDF (term frequency-inverse document frequency) of the word in the document the model generates the edges among nodes based on the word occurrence in the global corpus. Like in the traditional way in TF-IDF the term frequency represents the number of occurrences of the word in the document.to gather the co-occurrence statistics the model supplies a fixed size window on the documents in the corpus and the sliding of the window makes the global word co-occurrence information useful for prediction and classification. \n","\n","Mathematically the weight of an edge between node i and node j is defined as \n","\n","\n","![](https://149695847.v2.pressablecdn.com/wp-content/uploads/2021/11/image-16.png)\n","\n","We summarize the pipeline for using TextGCN to perform text classification as follows:\n","\n","1. **Preparation of text data**: cleaning data, removing stopwords, train-test split.\n","2. **Preparation of text graph**: buid a heterogenous graph based on the aforementioned formula.\n","3. **Model training**: create a GCN model with takes the text graph, node feature and edge weight to learn document embeddings."]},{"cell_type":"markdown","id":"17945f3c","metadata":{"id":"17945f3c"},"source":["## Data preparation"]},{"cell_type":"code","execution_count":null,"id":"f5c09b48","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f5c09b48","executionInfo":{"status":"ok","timestamp":1658764420142,"user_tz":-480,"elapsed":16803,"user":{"displayName":"Yu-Che Tsai","userId":"11097797349614937936"}},"outputId":"b8e9773f-51a3-4264-c73d-4f6361eca33a"},"outputs":[{"output_type":"stream","name":"stdout","text":["1.12.0+cu113\n"]}],"source":["# install packages\n","import os\n","import torch\n","os.environ['TORCH'] = torch.__version__\n","print(torch.__version__)\n","\n","!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n","!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n","!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n","!pip install -q torch-cluster -f https://data.pyg.org/whl/torch-${TORCH}.html"]},{"cell_type":"code","execution_count":null,"id":"ea01a9fb","metadata":{"id":"ea01a9fb"},"outputs":[],"source":["# import packages\n","import random\n","import numpy as np\n","import pickle as pkl\n","import torch\n","import scipy.sparse as sp\n","import pandas as pd \n","\n","from math import log\n","from collections import defaultdict\n","from torch_geometric.data import Data\n","from sklearn.preprocessing import LabelEncoder\n","from tqdm.auto import tqdm"]},{"cell_type":"code","execution_count":null,"id":"fb7914ef","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fb7914ef","executionInfo":{"status":"ok","timestamp":1658764420716,"user_tz":-480,"elapsed":5,"user":{"displayName":"Yu-Che Tsai","userId":"11097797349614937936"}},"outputId":"7f412c8d-43c6-4693-c98e-81ef3d78a00a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Data()"]},"metadata":{},"execution_count":3}],"source":["# create a empty Data object\n","pyg_data = Data()\n","pyg_data"]},{"cell_type":"code","execution_count":null,"id":"2ec041b3","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2ec041b3","executionInfo":{"status":"ok","timestamp":1658764423251,"user_tz":-480,"elapsed":2539,"user":{"displayName":"Yu-Che Tsai","userId":"11097797349614937936"}},"outputId":"a6deeb0f-f182-457c-fa66-024a606c10dc"},"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: destination path 'text_gcn.pytorch' already exists and is not an empty directory.\n","/content/text_gcn.pytorch/preprocess\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","{'its', \"doesn't\", 'while', \"hadn't\", 'hasn', 'if', 'through', 'than', 'this', 'yours', 'they', 'but', 'shouldn', 'm', \"mightn't\", 'we', 'same', 'themselves', \"weren't\", 'whom', 'their', 'have', 'did', 'any', 'those', 'i', 'more', 'against', 'can', 'didn', 'about', \"you've\", 'that', 'such', 'between', \"wouldn't\", 'it', 'below', 'not', 'too', 'her', 'above', 'our', 'himself', 'is', 'each', \"you'll\", 'theirs', 'under', 'for', 'herself', 'up', 'ain', 'hers', \"it's\", 'nor', \"wasn't\", 'having', 'again', 'so', 'ours', 'has', \"shouldn't\", 'an', \"didn't\", \"you'd\", 'hadn', \"mustn't\", 'itself', \"isn't\", 'being', 'these', 'yourself', \"don't\", 'all', 'needn', \"needn't\", 'no', 'or', 'during', 'haven', 'until', 'own', 'into', \"haven't\", 'only', 'will', 'a', 'him', \"hasn't\", 's', 'your', 'just', 'and', 'myself', 'd', 'doing', 'what', 'do', 't', \"couldn't\", \"shan't\", 'she', 'll', 'isn', 'doesn', 'ourselves', 'yourselves', 'very', 'couldn', 'was', 'who', 'wasn', 'now', 'mustn', 'be', \"won't\", 'from', 'further', 'y', 'because', 'down', \"she's\", 'of', 'with', 'mightn', \"that'll\", 'how', 'wouldn', 'few', 'were', 'as', \"aren't\", 'had', 'been', 'there', 'once', 'by', 'before', 'out', 'both', 'to', 've', 'won', 'on', 'aren', 'are', 'you', 'weren', 'at', 'them', 'other', 'over', 'after', 'here', 'o', 're', 'his', 'don', 'should', 'when', 'some', 'he', \"should've\", 'most', 'am', 'then', 'in', 'where', 'why', 'the', 'does', \"you're\", 'me', 'off', 'my', 'ma', 'shan', 'which'}\n","Min_len : 4\n","Max_len : 520\n","Average_len : 65.72126661454261\n","/content\n"]}],"source":["# download data\n","! git clone https://github.com/iworldtong/text_gcn.pytorch.git\n","%cd text_gcn.pytorch/preprocess/\n","! python remove_words.py R8\n","%cd ../../"]},{"cell_type":"code","execution_count":null,"id":"2c23c4f6","metadata":{"id":"2c23c4f6"},"outputs":[],"source":["dataset = \"R8\"\n","\n","# list for data\n","train_data = []\n","test_data = []\n","\n","with open('text_gcn.pytorch/data/' + dataset + '.txt', 'r') as f:\n","    lines = f.readlines()\n","    for line in lines:\n","        temp = line.strip().split(\"\\t\") # temp: [docID, Train/Test, target_class]\n","        if \"train\" in temp:\n","            train_data.append(temp)\n","        elif \"test\" in temp:\n","            test_data.append(temp)"]},{"cell_type":"code","execution_count":null,"id":"128cef77","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"128cef77","executionInfo":{"status":"ok","timestamp":1658764423252,"user_tz":-480,"elapsed":6,"user":{"displayName":"Yu-Che Tsai","userId":"11097797349614937936"}},"outputId":"2b53ec25-3028-47c6-962c-570cb6f04212"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[['0', 'train', 'earn'], ['1', 'train', 'acq'], ['2', 'train', 'earn']]"]},"metadata":{},"execution_count":6}],"source":["train_data[:3]"]},{"cell_type":"code","execution_count":null,"id":"bf4d301d","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bf4d301d","executionInfo":{"status":"ok","timestamp":1658764423252,"user_tz":-480,"elapsed":5,"user":{"displayName":"Yu-Che Tsai","userId":"11097797349614937936"}},"outputId":"8ee57d24-6fd1-4eff-8bbd-2db324fcade4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of documents 7674\n","Number of classes: 8\n"]}],"source":["# unpack train data\n","train_ids, _, train_target = zip(*train_data)\n","train_ids = np.array(list(map(int,train_ids)))\n","train_target = list(train_target)\n","\n","# unpack test data\n","test_ids, _, test_target = zip(*test_data)\n","test_ids = np.array(list(map(int,test_ids)))\n","test_target = list(test_target)\n","\n","# all ids\n","document_ids = np.append(train_ids,test_ids)\n","\n","# handling labels\n","label_list = train_target + test_target\n","enc = LabelEncoder()\n","label_list = enc.fit_transform(label_list)\n","train_target = enc.transform(train_target)\n","test_target = enc.transform(test_target)\n","\n","num_classes = len(enc.classes_)\n","print(\"Number of documents\",len(document_ids))\n","print(\"Number of classes:\",num_classes)\n","\n","# sizes\n","train_size = len(train_ids)\n","val_size = int(0.1 * train_size)\n","real_train_size = train_size - val_size\n","test_size = len(test_ids)"]},{"cell_type":"code","execution_count":null,"id":"28e2e869","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"28e2e869","executionInfo":{"status":"ok","timestamp":1658764423252,"user_tz":-480,"elapsed":4,"user":{"displayName":"Yu-Che Tsai","userId":"11097797349614937936"}},"outputId":"a1977a18-17cb-4cf3-ba49-c24b4b3977a8"},"outputs":[{"output_type":"stream","name":"stdout","text":["champion products approves stock split champion products inc said board directors approved two one stock split common shares shareholders record april company also said board voted recommend shareholders annual meeting april increase authorized capital stock five mln mln shares reuter\n"]}],"source":["# load document content from cleaned data\n","doc_content_list = []\n","with open('text_gcn.pytorch/data/corpus/' + dataset + '.clean.txt', 'r') as f:\n","    lines = f.readlines()\n","    for line in lines:\n","        doc_content_list.append(line.strip())\n","print(doc_content_list[0])"]},{"cell_type":"markdown","id":"94dabde9","metadata":{"id":"94dabde9"},"source":["## Build vocabulary\n","To create the text graph, we need to first calculate the TF and IDF as the edge weight."]},{"cell_type":"code","execution_count":null,"id":"0309c076","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0309c076","executionInfo":{"status":"ok","timestamp":1658764423720,"user_tz":-480,"elapsed":6,"user":{"displayName":"Yu-Che Tsai","userId":"11097797349614937936"}},"outputId":"85844c63-2ccd-4e52-a85b-9ca4b0c859d0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Vocaulary size: 7688\n"]}],"source":["# build vocabulary set and calculate word frequency\n","word_freq = {}\n","word_set = set()\n","for doc_words in doc_content_list:\n","    words = doc_words.split()\n","    for word in words:\n","        word_set.add(word)\n","        if word in word_freq:\n","            word_freq[word] += 1\n","        else:\n","            word_freq[word] = 1\n","\n","vocab = list(word_set)\n","vocab_size = len(vocab)\n","print(\"Vocaulary size:\",vocab_size)"]},{"cell_type":"code","execution_count":null,"id":"8b301cc6","metadata":{"id":"8b301cc6"},"outputs":[],"source":["# create document-word dictionary\n","word_doc_list = defaultdict(set)\n","\n","for i in range(len(doc_content_list)):\n","    doc_words = doc_content_list[i]\n","    words = doc_words.split()\n","    for word in words:\n","            word_doc_list[word].add(i)\n","\n","# calculate term frequency\n","word_doc_freq = {}\n","for word, doc_list in word_doc_list.items():\n","    word_doc_freq[word] = len(doc_list)\n","    \n","# word-index mapping\n","word_id_map = {}\n","for i in range(vocab_size):\n","    word_id_map[vocab[i]] = i\n","\n","vocab_str = '\\n'.join(vocab)"]},{"cell_type":"markdown","id":"fc9386e4","metadata":{"id":"fc9386e4"},"source":["# Heterogeneous graph construction\n","There are two types of node in the text graph: **Document node** and **Word node**.<br>\n","* Document-word edge: if a word appears in the document, create an edge between them. TF-IDF is used as the edge weight.\n","* Word-word edge: capturing the co-occurrence of words if they appeared in same document. PMI is used as edge weight.\n","\n","![](https://149695847.v2.pressablecdn.com/wp-content/uploads/2021/11/image-16.png)"]},{"cell_type":"code","execution_count":null,"id":"8977410a","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["842a3b947fc54c53ae5ebeae31b3ae20","2868c222fed84755b7b164f14ee1a492","b1db1989a22f4075adcae11ec08de43d","832486c3f99a409c89206befac01ccc4","ef0f8d86694842d892812c48c2213b1a","9f7936c2215a44de8222b54613e1e2a0","3cdd6f5eabe64297bce80eae97cfaba0","70ded8f774ac4fb3b7de0aa0abd2f1f9","b13b8d19fee34491aae334424c15d5ba","797453cc6113456daad257f6763dc31b","de05c41e9f484f7db5e5638f3f30bb88"]},"id":"8977410a","executionInfo":{"status":"ok","timestamp":1658764522951,"user_tz":-480,"elapsed":99234,"user":{"displayName":"Yu-Che Tsai","userId":"11097797349614937936"}},"outputId":"479d7e52-fc24-4c03-c74d-6775ab71565b"},"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/400703 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"842a3b947fc54c53ae5ebeae31b3ae20"}},"metadata":{}}],"source":["# word co-occurence with context windows\n","# store words in the same window\n","window_size = 15\n","windows = []\n","\n","for doc_words in doc_content_list:\n","    words = doc_words.split()\n","    length = len(words)\n","    if length <= window_size:\n","        windows.append(words)\n","    else:\n","        for j in range(length - window_size + 1):\n","            window = words[j: j + window_size]\n","            windows.append(window)\n","\n","# calculate p(word)\n","word_window_freq = {}\n","for window in windows:\n","    appeared = set()\n","    for i in range(len(window)):\n","        word = window[i]\n","        # continue if the frequency of the word has been calculated\n","        if word in appeared:\n","            continue\n","        if word in word_window_freq:\n","            word_window_freq[word] += 1\n","        else:\n","            word_window_freq[word] = 1\n","        appeared.add(word)\n","\n","# calculate co-occurrence frequency (i.e., p(i,j))\n","word_pair_count = {}\n","for window in tqdm(windows):\n","    for i in range(1, len(window)):\n","        for j in range(0, i):\n","            word_i = window[i]\n","            word_i_id = word_id_map[word_i]\n","            word_j = window[j]\n","            word_j_id = word_id_map[word_j]\n","            if word_i_id == word_j_id:\n","                continue\n","            word_pair_str = str(word_i_id) + ',' + str(word_j_id)\n","            if word_pair_str in word_pair_count:\n","                word_pair_count[word_pair_str] += 1\n","            else:\n","                word_pair_count[word_pair_str] = 1\n","            # two orders\n","            word_pair_str = str(word_j_id) + ',' + str(word_i_id)\n","            if word_pair_str in word_pair_count:\n","                word_pair_count[word_pair_str] += 1\n","            else:\n","                word_pair_count[word_pair_str] = 1"]},{"cell_type":"markdown","id":"42ac47ff","metadata":{"id":"42ac47ff"},"source":["## Creating wor-word edges and calculate edge weights"]},{"cell_type":"code","execution_count":null,"id":"cc67b061","metadata":{"id":"cc67b061"},"outputs":[],"source":["row = []\n","col = []\n","weight = []\n","\n","# pmi as weights\n","\n","num_window = len(windows)\n","\n","for key in word_pair_count:\n","    temp = key.split(',')\n","    i = int(temp[0])\n","    j = int(temp[1])\n","    count = word_pair_count[key]\n","    word_freq_i = word_window_freq[vocab[i]]\n","    word_freq_j = word_window_freq[vocab[j]]\n","    # PMI = p(i,j) / (p(i)*p(j))\n","    pmi = log((count / num_window) /\n","              (word_freq_i * word_freq_j/(num_window * num_window)))\n","    if pmi <= 0:\n","        continue\n","    row.append(train_size + i)\n","    col.append(train_size + j)\n","    weight.append(pmi)"]},{"cell_type":"code","execution_count":null,"id":"8c7d1f4c","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8c7d1f4c","executionInfo":{"status":"ok","timestamp":1658764529736,"user_tz":-480,"elapsed":6,"user":{"displayName":"Yu-Che Tsai","userId":"11097797349614937936"}},"outputId":"0eda26c9-215c-4121-d194-efb7229dd21c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of edges: 2432734\n"]}],"source":["print(\"Number of edges:\",len(row))"]},{"cell_type":"markdown","id":"16fc62fa","metadata":{"id":"16fc62fa"},"source":["## Creating word-document edges and calculate TF-IDF"]},{"cell_type":"code","execution_count":null,"id":"2171b9dc","metadata":{"id":"2171b9dc"},"outputs":[],"source":["# doc word frequency\n","doc_word_freq = defaultdict(lambda:0)\n","\n","for doc_id in document_ids:\n","    doc_words = doc_content_list[doc_id]\n","    words = doc_words.split()\n","    for word in words:\n","        word_id = word_id_map[word]\n","        doc_word_str = str(doc_id) + ',' + str(word_id)\n","        doc_word_freq[doc_word_str] += 1\n","\n","for doc_index in document_ids:\n","    doc_words = doc_content_list[doc_index]\n","    \n","    # avoid repeated calculation\n","    words = set(doc_words.split()) \n","    for word in words:\n","        word_index = word_id_map[word]\n","        key = str(doc_index) + ',' + str(word_index)\n","        freq = doc_word_freq[key]\n","        if doc_index < train_size:\n","            row.append(doc_index)\n","        else:\n","            row.append(doc_index + vocab_size)\n","        col.append(train_size + word_index)\n","        \n","        # TF-IDF as edge weight\n","        idf = log(1.0 * len(document_ids) /\n","                  word_doc_freq[vocab[word_index]])\n","        weight.append(freq * idf) # TF*IDF\n"]},{"cell_type":"code","execution_count":null,"id":"fcb4f685","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fcb4f685","executionInfo":{"status":"ok","timestamp":1658764531671,"user_tz":-480,"elapsed":5,"user":{"displayName":"Yu-Che Tsai","userId":"11097797349614937936"}},"outputId":"589d5386-b38d-43e1-b5be-a15197250361"},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of edges: 2756404\n"]}],"source":["print(\"Number of edges:\",len(row))"]},{"cell_type":"markdown","id":"7ee785a4","metadata":{"id":"7ee785a4"},"source":["### Storing all data in `pyg_data`"]},{"cell_type":"code","execution_count":null,"id":"e2f27f35","metadata":{"id":"e2f27f35"},"outputs":[],"source":["# nodes\n","node_size = train_size + vocab_size + test_size\n","pyg_data.num_nodes = node_size\n","\n","adj = sp.csr_matrix(\n","    (weight, (row, col)), shape=(node_size, node_size))\n","adj = adj + adj.T.multiply(adj.T > adj) - adj.multiply(adj.T > adj) # symmetric\n","\n","from torch_geometric.utils import from_scipy_sparse_matrix\n","edge_index, edge_weight = from_scipy_sparse_matrix(adj)\n","\n","pyg_data.edge_index = edge_index.long()\n","pyg_data.edge_weight = edge_weight.float()"]},{"cell_type":"code","execution_count":null,"id":"b0b00bfb","metadata":{"id":"b0b00bfb"},"outputs":[],"source":["# masks for training, testing\n","train_masks = torch.zeros(node_size).bool()\n","train_masks[train_ids] = 1\n","test_masks = torch.zeros(node_size).bool()\n","test_masks[test_ids+vocab_size] = 1 \n","\n","pyg_data.train_mask = train_masks\n","pyg_data.test_mask = test_masks\n","\n","# labels\n","pyg_data.num_classes = num_classes\n","targets = [torch.FloatTensor(train_target), torch.zeros(vocab_size), torch.FloatTensor(test_target)]\n","targets = torch.cat(targets,dim=0).long()\n","pyg_data.target = targets\n","assert targets.shape[0] == pyg_data.num_nodes\n","\n","# initial node feature\n","node_feature = torch.eye(pyg_data.num_nodes)\n","pyg_data.x = node_feature"]},{"cell_type":"code","execution_count":null,"id":"26be1bbd","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"26be1bbd","executionInfo":{"status":"ok","timestamp":1658764533432,"user_tz":-480,"elapsed":7,"user":{"displayName":"Yu-Che Tsai","userId":"11097797349614937936"}},"outputId":"7d7c688a-13ec-44e6-fda2-0614ac9bd9c7"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Data(num_nodes=15362, edge_index=[2, 3080074], edge_weight=[3080074], train_mask=[15362], test_mask=[15362], num_classes=8, target=[15362], x=[15362, 15362])"]},"metadata":{},"execution_count":18}],"source":["pyg_data"]},{"cell_type":"markdown","id":"501930b5","metadata":{"id":"501930b5"},"source":["## Practice: Training TextGCN model\n","So far, we prepare everything you need to train the TextGCN model. <br>\n","Please try to create a GCN model and perform the text classification as a node classification task.<br>"]},{"cell_type":"code","execution_count":null,"id":"10e720c4","metadata":{"id":"10e720c4"},"outputs":[],"source":["from torch_geometric.nn import GCNConv\n","import torch.nn.functional as F\n","import torch.nn as nn\n","\n","class TextGCN(torch.nn.Module):\n","    def __init__(self, in_channels, hidden_channels, out_channels):\n","        super().__init__()\n","        ############################################################################\n","        # TODO: Your code here! \n","        # create your GCN models here\n","        # Note: the input and output dimension is defined by the input parameters in_channels and out_channels\n","        self.conv1 = GCNConv(in_channels, hidden_channels, cached=True,\n","                             normalize=True)\n","        self.conv2 = GCNConv(hidden_channels, out_channels, cached=True,\n","                             normalize=True)\n","        ############################################################################\n","\n","    def forward(self, x, edge_index, edge_weight=None):\n","        ############################################################################\n","        # TODO: Your code here!       \n","        # define your forward pass logic here\n","        x = F.dropout(x, p=0.5, training=self.training)\n","        x = self.conv1(x, edge_index, edge_weight).relu()\n","        x = F.dropout(x, p=0.5, training=self.training)\n","        x = self.conv2(x, edge_index, edge_weight)\n","        ############################################################################\n","        return x"]},{"cell_type":"code","execution_count":null,"id":"2a66f4ac","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2a66f4ac","executionInfo":{"status":"ok","timestamp":1658764535488,"user_tz":-480,"elapsed":2059,"user":{"displayName":"Yu-Che Tsai","userId":"11097797349614937936"}},"outputId":"d68d6c2f-41a6-4b85-eaff-966e8ad127b4"},"outputs":[{"output_type":"stream","name":"stdout","text":["TextGCN(\n","  (conv1): GCNConv(15362, 200)\n","  (conv2): GCNConv(200, 8)\n",")\n"]}],"source":["# model configurations\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","dim = None \n","model = None\n","optimizer = None\n","criterion = None \n","############################################################################\n","# TODO: Your code here!  \n","# setup the model, optimizer, objective functions here\n","# Note: you should be careful with the loss function with its \"reduction\" parameter!\n","#       since we cannot use the embeddings from testing nodes with training mask\n","dim = 200\n","model = TextGCN(pyg_data.num_nodes, dim, pyg_data.num_classes).to(device)\n","optimizer = torch.optim.Adam(model.parameters(),lr=0.02)\n","criterion = nn.CrossEntropyLoss(reduction=\"none\")\n","############################################################################\n","print(model)"]},{"cell_type":"code","execution_count":null,"id":"f6158177","metadata":{"id":"f6158177"},"outputs":[],"source":["# map data to GPU device\n","pyg_data.x = pyg_data.x.to(device)\n","pyg_data.edge_index = pyg_data.edge_index.to(device)\n","pyg_data.edge_weight = pyg_data.edge_weight.to(device)\n","pyg_data.target = pyg_data.target.to(device)"]},{"cell_type":"code","execution_count":null,"id":"b3bfde67","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b3bfde67","executionInfo":{"status":"ok","timestamp":1658764575295,"user_tz":-480,"elapsed":39809,"user":{"displayName":"Yu-Che Tsai","userId":"11097797349614937936"}},"outputId":"d52cad3a-c42b-491b-ba1b-03a0cb04bc1c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train Accuracy:0.0886 | Test Accuracy:0.1046\n","Train Accuracy:0.6445 | Test Accuracy:0.6176\n","Train Accuracy:0.5858 | Test Accuracy:0.5546\n","Train Accuracy:0.5391 | Test Accuracy:0.5148\n","Train Accuracy:0.5229 | Test Accuracy:0.4957\n","Train Accuracy:0.5192 | Test Accuracy:0.4947\n","Train Accuracy:0.5192 | Test Accuracy:0.4957\n","Train Accuracy:0.5335 | Test Accuracy:0.5016\n","Train Accuracy:0.6170 | Test Accuracy:0.5710\n","Train Accuracy:0.7129 | Test Accuracy:0.6962\n","Train Accuracy:0.7526 | Test Accuracy:0.7460\n","Train Accuracy:0.7599 | Test Accuracy:0.7624\n","Train Accuracy:0.7665 | Test Accuracy:0.7739\n","Train Accuracy:0.7690 | Test Accuracy:0.7734\n","Train Accuracy:0.7721 | Test Accuracy:0.7757\n","Train Accuracy:0.7739 | Test Accuracy:0.7725\n","Train Accuracy:0.7747 | Test Accuracy:0.7739\n","Train Accuracy:0.7796 | Test Accuracy:0.7784\n","Train Accuracy:0.7798 | Test Accuracy:0.7848\n","Train Accuracy:0.7825 | Test Accuracy:0.7876\n","Train Accuracy:0.7827 | Test Accuracy:0.7853\n","Train Accuracy:0.7830 | Test Accuracy:0.7944\n","Train Accuracy:0.7847 | Test Accuracy:0.7921\n","Train Accuracy:0.7849 | Test Accuracy:0.7940\n","Train Accuracy:0.7849 | Test Accuracy:0.7935\n","Train Accuracy:0.7887 | Test Accuracy:0.7926\n","Train Accuracy:0.7892 | Test Accuracy:0.7944\n","Train Accuracy:0.7903 | Test Accuracy:0.7958\n","Train Accuracy:0.7891 | Test Accuracy:0.7976\n","Train Accuracy:0.7902 | Test Accuracy:0.8008\n","Train Accuracy:0.7918 | Test Accuracy:0.7995\n","Train Accuracy:0.7938 | Test Accuracy:0.7995\n","Train Accuracy:0.8000 | Test Accuracy:0.8054\n","Train Accuracy:0.8084 | Test Accuracy:0.8063\n","Train Accuracy:0.8199 | Test Accuracy:0.8255\n","Train Accuracy:0.8357 | Test Accuracy:0.8433\n","Train Accuracy:0.8390 | Test Accuracy:0.8552\n","Train Accuracy:0.8487 | Test Accuracy:0.8611\n","Train Accuracy:0.8565 | Test Accuracy:0.8616\n","Train Accuracy:0.8609 | Test Accuracy:0.8625\n","Train Accuracy:0.8636 | Test Accuracy:0.8634\n","Train Accuracy:0.8665 | Test Accuracy:0.8698\n","Train Accuracy:0.8747 | Test Accuracy:0.8730\n","Train Accuracy:0.8755 | Test Accuracy:0.8748\n","Train Accuracy:0.8817 | Test Accuracy:0.8808\n","Train Accuracy:0.8861 | Test Accuracy:0.8840\n","Train Accuracy:0.8855 | Test Accuracy:0.8844\n","Train Accuracy:0.8926 | Test Accuracy:0.8881\n","Train Accuracy:0.8994 | Test Accuracy:0.8972\n","Train Accuracy:0.9088 | Test Accuracy:0.9068\n","Train Accuracy:0.9130 | Test Accuracy:0.9082\n","Train Accuracy:0.9185 | Test Accuracy:0.9109\n","Train Accuracy:0.9222 | Test Accuracy:0.9150\n","Train Accuracy:0.9203 | Test Accuracy:0.9118\n","Train Accuracy:0.9240 | Test Accuracy:0.9150\n","Train Accuracy:0.9265 | Test Accuracy:0.9223\n","Train Accuracy:0.9351 | Test Accuracy:0.9278\n","Train Accuracy:0.9389 | Test Accuracy:0.9310\n","Train Accuracy:0.9406 | Test Accuracy:0.9370\n","Train Accuracy:0.9373 | Test Accuracy:0.9310\n","Train Accuracy:0.9448 | Test Accuracy:0.9338\n","Train Accuracy:0.9453 | Test Accuracy:0.9434\n","Train Accuracy:0.9486 | Test Accuracy:0.9342\n","Train Accuracy:0.9480 | Test Accuracy:0.9424\n","Train Accuracy:0.9484 | Test Accuracy:0.9360\n","Train Accuracy:0.9561 | Test Accuracy:0.9429\n","Train Accuracy:0.9557 | Test Accuracy:0.9447\n","Train Accuracy:0.9524 | Test Accuracy:0.9429\n","Train Accuracy:0.9546 | Test Accuracy:0.9447\n","Train Accuracy:0.9579 | Test Accuracy:0.9534\n","Train Accuracy:0.9575 | Test Accuracy:0.9461\n","Train Accuracy:0.9606 | Test Accuracy:0.9479\n","Train Accuracy:0.9610 | Test Accuracy:0.9438\n","Train Accuracy:0.9595 | Test Accuracy:0.9484\n","Train Accuracy:0.9650 | Test Accuracy:0.9539\n","Train Accuracy:0.9617 | Test Accuracy:0.9520\n","Train Accuracy:0.9661 | Test Accuracy:0.9511\n","Train Accuracy:0.9626 | Test Accuracy:0.9534\n","Train Accuracy:0.9679 | Test Accuracy:0.9520\n","Train Accuracy:0.9696 | Test Accuracy:0.9529\n","Train Accuracy:0.9686 | Test Accuracy:0.9529\n","Train Accuracy:0.9701 | Test Accuracy:0.9561\n","Train Accuracy:0.9712 | Test Accuracy:0.9561\n","Train Accuracy:0.9677 | Test Accuracy:0.9557\n","Train Accuracy:0.9706 | Test Accuracy:0.9529\n","Train Accuracy:0.9721 | Test Accuracy:0.9529\n","Train Accuracy:0.9712 | Test Accuracy:0.9552\n","Train Accuracy:0.9741 | Test Accuracy:0.9534\n","Train Accuracy:0.9758 | Test Accuracy:0.9648\n","Train Accuracy:0.9759 | Test Accuracy:0.9625\n","Train Accuracy:0.9761 | Test Accuracy:0.9575\n","Train Accuracy:0.9759 | Test Accuracy:0.9580\n","Train Accuracy:0.9745 | Test Accuracy:0.9589\n","Train Accuracy:0.9783 | Test Accuracy:0.9584\n","Train Accuracy:0.9781 | Test Accuracy:0.9566\n","Train Accuracy:0.9785 | Test Accuracy:0.9580\n","Train Accuracy:0.9765 | Test Accuracy:0.9630\n","Train Accuracy:0.9787 | Test Accuracy:0.9593\n","Train Accuracy:0.9803 | Test Accuracy:0.9598\n","Train Accuracy:0.9792 | Test Accuracy:0.9625\n","Train Accuracy:0.9812 | Test Accuracy:0.9630\n","Train Accuracy:0.9832 | Test Accuracy:0.9630\n","Train Accuracy:0.9794 | Test Accuracy:0.9635\n","Train Accuracy:0.9785 | Test Accuracy:0.9584\n","Train Accuracy:0.9805 | Test Accuracy:0.9612\n","Train Accuracy:0.9812 | Test Accuracy:0.9593\n","Train Accuracy:0.9832 | Test Accuracy:0.9625\n","Train Accuracy:0.9807 | Test Accuracy:0.9648\n","Train Accuracy:0.9805 | Test Accuracy:0.9648\n","Train Accuracy:0.9816 | Test Accuracy:0.9644\n","Train Accuracy:0.9803 | Test Accuracy:0.9625\n","Train Accuracy:0.9845 | Test Accuracy:0.9621\n","Train Accuracy:0.9832 | Test Accuracy:0.9566\n","Train Accuracy:0.9834 | Test Accuracy:0.9557\n","Train Accuracy:0.9829 | Test Accuracy:0.9621\n","Train Accuracy:0.9863 | Test Accuracy:0.9662\n","Train Accuracy:0.9838 | Test Accuracy:0.9616\n","Train Accuracy:0.9856 | Test Accuracy:0.9616\n","Train Accuracy:0.9860 | Test Accuracy:0.9621\n","Train Accuracy:0.9854 | Test Accuracy:0.9635\n","Train Accuracy:0.9830 | Test Accuracy:0.9653\n","Train Accuracy:0.9869 | Test Accuracy:0.9625\n","Train Accuracy:0.9863 | Test Accuracy:0.9603\n","Train Accuracy:0.9843 | Test Accuracy:0.9603\n","Train Accuracy:0.9869 | Test Accuracy:0.9603\n","Train Accuracy:0.9860 | Test Accuracy:0.9593\n","Train Accuracy:0.9854 | Test Accuracy:0.9571\n","Train Accuracy:0.9860 | Test Accuracy:0.9644\n","Train Accuracy:0.9858 | Test Accuracy:0.9648\n","Train Accuracy:0.9845 | Test Accuracy:0.9625\n","Train Accuracy:0.9861 | Test Accuracy:0.9621\n","Train Accuracy:0.9878 | Test Accuracy:0.9639\n","Train Accuracy:0.9869 | Test Accuracy:0.9584\n","Train Accuracy:0.9852 | Test Accuracy:0.9548\n","Train Accuracy:0.9885 | Test Accuracy:0.9676\n","Train Accuracy:0.9894 | Test Accuracy:0.9612\n","Train Accuracy:0.9883 | Test Accuracy:0.9644\n","Train Accuracy:0.9887 | Test Accuracy:0.9662\n","Train Accuracy:0.9872 | Test Accuracy:0.9648\n","Train Accuracy:0.9889 | Test Accuracy:0.9625\n","Train Accuracy:0.9876 | Test Accuracy:0.9644\n","Train Accuracy:0.9885 | Test Accuracy:0.9616\n","Train Accuracy:0.9856 | Test Accuracy:0.9616\n","Train Accuracy:0.9891 | Test Accuracy:0.9584\n","Train Accuracy:0.9900 | Test Accuracy:0.9635\n","Train Accuracy:0.9907 | Test Accuracy:0.9657\n","Train Accuracy:0.9909 | Test Accuracy:0.9648\n","Train Accuracy:0.9892 | Test Accuracy:0.9598\n","Train Accuracy:0.9896 | Test Accuracy:0.9612\n","Train Accuracy:0.9903 | Test Accuracy:0.9685\n","Train Accuracy:0.9912 | Test Accuracy:0.9593\n","Train Accuracy:0.9912 | Test Accuracy:0.9607\n","Train Accuracy:0.9909 | Test Accuracy:0.9598\n","Train Accuracy:0.9920 | Test Accuracy:0.9607\n","Train Accuracy:0.9920 | Test Accuracy:0.9616\n","Train Accuracy:0.9903 | Test Accuracy:0.9644\n","Train Accuracy:0.9907 | Test Accuracy:0.9635\n","Train Accuracy:0.9907 | Test Accuracy:0.9612\n","Train Accuracy:0.9911 | Test Accuracy:0.9625\n","Train Accuracy:0.9903 | Test Accuracy:0.9639\n","Train Accuracy:0.9916 | Test Accuracy:0.9671\n","Train Accuracy:0.9918 | Test Accuracy:0.9653\n","Train Accuracy:0.9927 | Test Accuracy:0.9616\n","Train Accuracy:0.9925 | Test Accuracy:0.9616\n","Train Accuracy:0.9936 | Test Accuracy:0.9625\n","Train Accuracy:0.9922 | Test Accuracy:0.9584\n","Train Accuracy:0.9931 | Test Accuracy:0.9566\n","Train Accuracy:0.9918 | Test Accuracy:0.9612\n","Train Accuracy:0.9940 | Test Accuracy:0.9621\n","Train Accuracy:0.9923 | Test Accuracy:0.9635\n","Train Accuracy:0.9936 | Test Accuracy:0.9657\n","Train Accuracy:0.9920 | Test Accuracy:0.9648\n","Train Accuracy:0.9929 | Test Accuracy:0.9598\n","Train Accuracy:0.9934 | Test Accuracy:0.9644\n","Train Accuracy:0.9929 | Test Accuracy:0.9580\n","Train Accuracy:0.9923 | Test Accuracy:0.9612\n","Train Accuracy:0.9914 | Test Accuracy:0.9680\n","Train Accuracy:0.9938 | Test Accuracy:0.9566\n","Train Accuracy:0.9933 | Test Accuracy:0.9584\n","Train Accuracy:0.9940 | Test Accuracy:0.9671\n","Train Accuracy:0.9929 | Test Accuracy:0.9630\n","Train Accuracy:0.9938 | Test Accuracy:0.9589\n","Train Accuracy:0.9938 | Test Accuracy:0.9653\n","Train Accuracy:0.9931 | Test Accuracy:0.9612\n","Train Accuracy:0.9929 | Test Accuracy:0.9621\n","Train Accuracy:0.9945 | Test Accuracy:0.9607\n","Train Accuracy:0.9945 | Test Accuracy:0.9580\n","Train Accuracy:0.9945 | Test Accuracy:0.9635\n","Train Accuracy:0.9938 | Test Accuracy:0.9635\n","Train Accuracy:0.9931 | Test Accuracy:0.9607\n","Train Accuracy:0.9945 | Test Accuracy:0.9607\n","Train Accuracy:0.9938 | Test Accuracy:0.9644\n","Train Accuracy:0.9929 | Test Accuracy:0.9593\n","Train Accuracy:0.9938 | Test Accuracy:0.9593\n","Train Accuracy:0.9938 | Test Accuracy:0.9589\n","Train Accuracy:0.9938 | Test Accuracy:0.9589\n","Train Accuracy:0.9949 | Test Accuracy:0.9607\n","Train Accuracy:0.9947 | Test Accuracy:0.9607\n","Train Accuracy:0.9929 | Test Accuracy:0.9575\n","Train Accuracy:0.9960 | Test Accuracy:0.9616\n"]}],"source":["for epoch in range(200):\n","    logits = model(pyg_data.x, pyg_data.edge_index, pyg_data.edge_weight)\n","    loss = criterion(logits, pyg_data.target)[pyg_data.train_mask]\n","    loss = loss.mean()    \n","    \n","    # Backward and optimize\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","    \n","    # evaluation\n","    train_accuracy = None\n","    test_accuracy = None\n","    ############################################################################\n","    # TODO: Your code here!  \n","    # calculate the train/test accuracy\n","    accurate_prediction = (torch.max(logits, 1)[1] == pyg_data.target)\n","    train_accuracy = accurate_prediction[pyg_data.train_mask].float().mean().item()\n","    test_accuracy = accurate_prediction[pyg_data.test_mask].float().mean().item()\n","    ############################################################################\n","    print(f\"Train Accuracy:{train_accuracy:.4f} | Test Accuracy:{test_accuracy:.4f}\")"]},{"cell_type":"markdown","id":"26a90a56","metadata":{"id":"26a90a56"},"source":["## Additional questions\n","If you already finish the above exercise, try to answer the follwing questions!\n","* How many GCN layers achieves the best performance?\n","* Does the window size effect the performance? What happens if we increase or decrease the window size?\n","* What are the limitations of TextGCN?"]},{"cell_type":"markdown","id":"ba17ea45","metadata":{"id":"ba17ea45"},"source":["## My short answer\n","* How many GCN layers achieves the best performance?\n","According to the paper, two-layer GCN usually achieves the best performance.\n","* Does the window size effect the performance? What happens if we increase or decrease the window size?\n","The text graph becomes much more dense as we increase the window size and vice versa. <br>\n","A dense graph might include noisy signals/information that dampens the final performance.\n","* What are the limitations of TextGCN?\n","It is transductive in nature, which means we cannot deal with unseen document nodes that was not appeared in thi"]},{"cell_type":"code","source":[],"metadata":{"id":"TFzxQuX6VXzi"},"id":"TFzxQuX6VXzi","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"colab":{"provenance":[],"collapsed_sections":[]},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"842a3b947fc54c53ae5ebeae31b3ae20":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2868c222fed84755b7b164f14ee1a492","IPY_MODEL_b1db1989a22f4075adcae11ec08de43d","IPY_MODEL_832486c3f99a409c89206befac01ccc4"],"layout":"IPY_MODEL_ef0f8d86694842d892812c48c2213b1a"}},"2868c222fed84755b7b164f14ee1a492":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9f7936c2215a44de8222b54613e1e2a0","placeholder":"​","style":"IPY_MODEL_3cdd6f5eabe64297bce80eae97cfaba0","value":"100%"}},"b1db1989a22f4075adcae11ec08de43d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_70ded8f774ac4fb3b7de0aa0abd2f1f9","max":400703,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b13b8d19fee34491aae334424c15d5ba","value":400703}},"832486c3f99a409c89206befac01ccc4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_797453cc6113456daad257f6763dc31b","placeholder":"​","style":"IPY_MODEL_de05c41e9f484f7db5e5638f3f30bb88","value":" 400703/400703 [01:35&lt;00:00, 4518.45it/s]"}},"ef0f8d86694842d892812c48c2213b1a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f7936c2215a44de8222b54613e1e2a0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3cdd6f5eabe64297bce80eae97cfaba0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"70ded8f774ac4fb3b7de0aa0abd2f1f9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b13b8d19fee34491aae334424c15d5ba":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"797453cc6113456daad257f6763dc31b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"de05c41e9f484f7db5e5638f3f30bb88":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}